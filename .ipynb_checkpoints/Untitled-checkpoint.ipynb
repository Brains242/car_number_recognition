{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b233bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daefcc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "148e922c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_index = 35\n",
    "print(y_train[image_index])\n",
    "plt.imshow(x_train[image_index], cmap='Greys')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62421d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3973863d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7 3 8 6 9 0 5]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:image_index + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "957892e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23920e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "num_classes = 10\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "717956b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), \n",
    "                 activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "622fd0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd6d8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6653344",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afd92c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aba3db4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must have the same first dimension, got logits shape [128,10] and labels shape [12800]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at c:\\users\\administrator\\venvs\\car_number_recognition\\lib\\site-packages\\keras\\backend.py:4944) ]] [Op:__inference_train_function_1939]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:\n sparse_categorical_crossentropy/Reshape_1 (defined at c:\\users\\administrator\\venvs\\car_number_recognition\\lib\\site-packages\\keras\\backend.py:4940)\t\n sparse_categorical_crossentropy/Reshape (defined at c:\\users\\administrator\\venvs\\car_number_recognition\\lib\\site-packages\\keras\\backend.py:3400)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_12272/888836147.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m model.fit(x_train, y_train,\n\u001b[0m\u001b[0;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\venvs\\car_number_recognition\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1156\u001b[0m                 _r=1):\n\u001b[0;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\venvs\\car_number_recognition\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\venvs\\car_number_recognition\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\venvs\\car_number_recognition\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\venvs\\car_number_recognition\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\administrator\\venvs\\car_number_recognition\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\venvs\\car_number_recognition\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  logits and labels must have the same first dimension, got logits shape [128,10] and labels shape [12800]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at c:\\users\\administrator\\venvs\\car_number_recognition\\lib\\site-packages\\keras\\backend.py:4944) ]] [Op:__inference_train_function_1939]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:\n sparse_categorical_crossentropy/Reshape_1 (defined at c:\\users\\administrator\\venvs\\car_number_recognition\\lib\\site-packages\\keras\\backend.py:4940)\t\n sparse_categorical_crossentropy/Reshape (defined at c:\\users\\administrator\\venvs\\car_number_recognition\\lib\\site-packages\\keras\\backend.py:3400)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 1\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save(\"test_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4467f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d08ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
